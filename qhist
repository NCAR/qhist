#!/usr/bin/env python2

import sys, argparse, subprocess, copy, re
from datetime import datetime, timedelta
from itertools import izip
from signal import signal, SIGPIPE, SIG_DFL
from collections import defaultdict
from operator import itemgetter

# Use default signal behavior on system rather than throwing IOError
signal(SIGPIPE, SIG_DFL)

# System constants
pbslog_path = "/gpfs/pbs/server_priv/accounting/"
log_start   = datetime(2016, 12, 10)
cur_date    = datetime.today()
pbsdate_fmt = "%Y%m%d"

# Operational constants
time_vars   = ["submit","start","finish","eligible"]
one_day     = timedelta(days = 1)

# Output field class
class field:
    def __init__(self, long_label, long_fmt = "{}", short_fmt = "{}", short_label = ""):
        self.long_label     = long_label
        self.long_fmt       = long_fmt
        self.short_fmt      = short_fmt

        if short_label:
            self.short_label    = short_label
        else:
            self.short_label    = long_label

# Job parameters and argument dictionary storage
param_list  = [ "user","queue","Resource_List.nodect","ctime","start","end",
                "resources_used.mem","resources_used.cpupercent",
                "resources_used.walltime","jobname","Exit_status","account",
                "Resource_List.select","exec_vnode" ]
proc_names  = { "Resource_List.nodect"      : "nodes",
                "ctime"                     : "submit",
                "etime"                     : "eligible",
                "end"                       : "finish",
                "resources_used.mem"        : "memory",
                "resources_used.cpupercent" : "cpu",
                "resources_used.walltime"   : "walltime",
                "jobname"                   : "name",
                "Exit_status"               : "status",
                "Resource_List.select"      : "resources",
                "exec_vnode"                : "nodelist" }
data_fmt    = { "nodes"     : "{:d}",
                "memory"    : "{:0.1f}",
                "cpu"       : "{:0.1f}",
                "walltime"  : "{:d}" }
field_data  = { "id"        : field("Job ID"),
                "user"      : field("User",         "{:15.15}",     "{:7.7}"),
                "queue"     : field("Queue",        "{:10.10}",     "{:7.7}"),
                "nodes"     : field("Nodes",        "{:>5.5}",      "{:>5.5}"),
                "submit"    : field("Submit Time",  "{:12.12}",     "{:7.7}",   "Submit"),
                "eligible"  : field("Eligible Time","{:12.12}",     "{:7.7}",   "Elig."),
                "start"     : field("Start Time",   "{:12.12}",     "{:7.7}",   "Start"),
                "finish"    : field("Finish Time",  "{:12.12}",     "{:7.7}",   "Finish"),
                "memory"    : field("Mem/Node(GB)", "{:>12.12}",    "{:>7.7}",  "Mem(GB)"),
                "cpu"       : field("CPU/Node (%)", "{:>12.12}",    "{:>7.7}",  "CPU(%)"),
                "walltime"  : field("Walltime (s)", "{:>12.12}",    "{:>7.7}",  "Wall(s)"),
                "name"      : field("Job Name"),
                "status"    : field("Exit Status"),
                "account"   : field("Account"),
                "resources" : field("Resources"),
                "nodelist"  : field("Node List")}
arg_help    = { "account"   : "filter jobs by a specific account/project code",
                "average"   : "print average resource statistics in standard view",
                "brief"     : "only output the PBS job IDs",
                "days"      : "number of days prior to search (default = 0)",
                "failures"  : "only print jobs with non-zero PBS exit codes",
                "job"       : "only display output for a specific job ID",
                "list"      : "display untruncated output in list format",
                "momlist"   : "only print jobs that ran on specified plus-delimited list of nodes",
                "nodes"     : "show list of nodes for each job",
                "period"    : "search over specific date range (YYYYMMDD-YYYYMMDD)",
                "requeues"  : "include run attempts that result in PBS requeues",
                "sort"      : "sort by id, user, queue, nodes, submit, start, finish, memory, cpu, walltime, or name",
                "user"      : "filter jobs by a specific user",
                "wide"      : "use wide table columns and show job names" }

#
## FUNCTION DEFINITIONS
#

def run_grep(log, requeues):
    if requeues:
        proc = subprocess.Popen(["grep", "-a", "-e", ";R;", "-e", ";E;", log],
                stdout = subprocess.PIPE, stderr = subprocess.STDOUT)
    else:
        proc = subprocess.Popen(["grep", "-a", ";E;", log],
                stdout = subprocess.PIPE, stderr = subprocess.STDOUT)

    out_data = proc.communicate()[0]
    return proc.returncode, out_data

def get_time_bounds(args):
    if args.period and '-' in args.period:
        try:
            bounds = [datetime.strptime(d, pbsdate_fmt) for
                        d in args.period.split('-')]
        except ValueError:
            print "Date range not in a valid format..."
            print "    showing today's jobs instead\n"
            bounds = [cur_date - one_day, cur_date]
    else:
        bounds = [cur_date - one_day * int(args.days), cur_date]
        
    # Check to make sure bounds fit into range
    if bounds[0] < log_start:
        print "Starting date preceeds beginning of logs..."
        print "    using {} instead\n".format(log_start.strftime(pbsdate_fmt))
        bounds[0] = log_start
    
    if bounds[1] > cur_date:
        print "Ending date is in the future..."
        print "    using today instead\n"
        bounds[1] = cur_date
    
    return bounds

def filter_log(log_data, include, exclude):
    post_data = []

    for entry in log_data:
        in_pass = all(item in entry for item in include)
        ex_pass = not any(item in entry for item in exclude)

        if in_pass and ex_pass:
            post_data.append(entry)
    
    return post_data

def format_log(jobs, time_fmt):
    for record in jobs:
        for tv in time_vars:
            record[tv] = datetime.strftime(record[tv], time_fmt)

        for dv in data_fmt:
            record[dv] = data_fmt[dv].format(record[dv])

def sort_log(jobs, method):
    # Get sort index based on method
    if method in jobs[0]:
        jobs.sort(key = itemgetter(method), reverse = True)
    else:
        print "Sorting method {} not recognized...".format(method)
        print "    using finish time instead\n"

def process_log(log_data, requeues):
    jobs    = []
    records = {}
    nodes   = 0

    for entry in log_data:
        records["id"], job_data = entry.split(';')[2:4]

        for item in job_data.split():
            param, content = item.split('=', 1)
            
            if param in proc_names:
                param = proc_names[param]

            if param in time_vars:
                content = datetime.fromtimestamp(float(content))
            elif param == "nodes":
                content = int(content)
            elif param == "walltime":
                tvals   = [int(val) for val in content.split(":")]
                content = tvals[0] * 3600 + tvals[1] * 60 + tvals[2]
            elif param == "memory":
                content = (float(content[:-2]) / 1048576) / records["nodes"]
            elif param == "cpu":
                content = float(content) / records["nodes"] / 36
            elif param == "nodelist":
                content = '+'.join([n[1:].split(':')[0] for n in content.split('+')])
            elif param == "account":
                content = content.replace('"','')

            records[param] = content

        if requeues:
            records["id"] = "{};{}".format(records["id"], entry.split(';')[1])

        jobs.append(records.copy())
    
    # Check if item is already in jobs (requeues result in dups)
    if requeues:
        jobsub  = [(j["id"],j["start"],j["finish"]) for j in jobs]
        dups    = defaultdict(list)
        dupinds = []

        for i, e in enumerate(jobsub):
            dups[e].append(i)

        for d in dups.iteritems():
            dupinds += d[1][1:]

        for n in sorted(dupinds, reverse = True):
            del jobs[n]

    return jobs

def print_list(jobs, my_fields, job_stats):
    labels      = [field_data[f].long_label for f in my_fields]
    len_max     = max(len(item) for item in labels)
    fmt_str     = "   {:" + str(len_max) + "} {} {}"

    for record in jobs:
        for l, r in izip(labels, [record[f] for f in my_fields]):
            if l == "Job ID":
                print r
            else:
                print fmt_str.format(l, '=', r)
        
        print

    if job_stats:
        for f in job_stats:
            if f == "id":
                print("Averages Weighted by Job Cost")
            else:
                print fmt_str.format(field_data[f].long_label, '=', job_stats[f])
        
        print

def print_table(jobs, my_fields, my_fmt, args):
    for record in jobs:
        print my_fmt.format(*[record[f] for f in my_fields])

        if args.nodes:
            print "    {}".format(record["nodelist"])

def compute_stats(jobs):
    job_stats = {f : 0.0 for f in ("nodes","memory","cpu","walltime")}
    wght_sum  = 0.0

    for job in jobs:
        weight      =   job["nodes"] * job["walltime"]
        wght_sum    +=  weight

        for n in list(job_stats):
            job_stats[n] += job[n] * weight
    
    for n in list(job_stats):
        job_stats[n] = "{:0.1f}".format(job_stats[n] / wght_sum)

    job_stats["id"] = "Average"

    return job_stats

#
## MAIN PROGRAM EXECUTION
#

if __name__ == "__main__":
    # Define command line arguments
    parser = argparse.ArgumentParser(prog = "qhist",                    
                description = "Search PBS logs for finished jobs.")

    # Optional arguments
    parser.add_argument("--account", help = arg_help["account"])
    parser.add_argument("-a", "--average", help = arg_help["average"],
            action = "store_true")
    parser.add_argument("-b", "--brief", help = arg_help["brief"],
            action = "store_true")
    parser.add_argument("-d", "--days", help = arg_help["days"],
            default = 0)
    parser.add_argument("-f", "--failures", help = arg_help["failures"],
            action = "store_true")
    parser.add_argument("-j", "--job", help = arg_help["job"])
    parser.add_argument("-l", "--list", help = arg_help["list"],
            action = "store_true")
    parser.add_argument("-m", "--momlist", help = arg_help["momlist"])
    parser.add_argument("-n", "--nodes", help = arg_help["nodes"],
            action = "store_true")
    parser.add_argument("-p", "--period", help = arg_help["period"])
    parser.add_argument("-r", "--requeues", help = arg_help["requeues"],
            action = "store_true")
    parser.add_argument("-s", "--sort", help = arg_help["sort"],
            default = "finish")
    parser.add_argument("-u", "--user", help = arg_help["user"])
    parser.add_argument("-w", "--wide", help = arg_help["wide"],
            action = "store_true")

    # Handle job ID and log path arguments
    args = parser.parse_args()

    # Collect search terms
    include = []
    exclude = []
    
    if args.account:
        include += ['account="{}" '.format(args.account)]

    if args.user:
        include += ["user={} ".format(args.user)]
    
    if args.job:
        include += [";{}".format(args.job)]
    
    if args.momlist:
        include += args.momlist.split('+')

    if args.failures:
        exclude += ["Exit_status=0 "]

    # Get start and end files
    bounds      = get_time_bounds(args)
    loop_date   = bounds[0]
    log_data    = []

    while loop_date <= bounds[1]:
        log                 = pbslog_path + datetime.strftime(loop_date, pbsdate_fmt)
        status, raw_data    = run_grep(log, args.requeues)

        if status == 0:
            log_data += filter_log(raw_data.splitlines(), include, exclude)

        loop_date += one_day
    
    if len(log_data) > 0:
        jobs = process_log(log_data, args.requeues)

        # Sort, format and print log 
        sort_log(jobs, args.sort)
        
        if args.brief:
            for record in jobs:
                print re.sub('\.[^;]*', '', record["id"])
        else:
            if args.average:
                job_stats = compute_stats(jobs)
            else:
                job_stats = None

            if args.list:
                format_log(jobs, "%Y-%m-%dT%H:%M:%S")
                my_fields = (   "id", "user", "queue", "nodes", "submit", "eligible",
                                "start", "finish", "memory", "cpu", "walltime",
                                "name", "status", "account", "resources", "nodelist" )
    
                print_list(jobs, my_fields, job_stats)
            else:
                # Process job names and get max length for formatting
                if args.wide:
                    format_log(jobs, "%b-%dT%H:%M")
                    my_fields   = ( "id", "user", "queue", "nodes", "submit", "start",
                                    "finish", "memory", "cpu", "walltime", "name" )
                    proc_reg    = '\.[^;]*'
                    my_fmt      = "  ".join([field_data[f].long_fmt for f in my_fields[1:]])
                    my_labels   = [field_data[f].long_label for f in my_fields]
                else:
                    format_log(jobs, "%d-%H%M")
                    my_fields   = ( "id", "user", "queue", "nodes", "submit", "start",
                                    "finish", "memory", "cpu", "walltime" )
                    proc_reg    = '[\.\[][^;]*'
                    my_fmt      = "  ".join([field_data[f].short_fmt for f in my_fields[1:]])
                    my_labels   = [field_data[f].short_label for f in my_fields]
                
                for item in jobs:
                    item["id"] = re.sub(proc_reg, '', item["id"])

                my_fmt = "{{:{0}.{0}}}  ".format(max(len(item["id"]) for item in jobs)) + my_fmt
              
                print my_fmt.format(*my_labels)
                print_table(jobs, my_fields, my_fmt, args)

                if args.average:
                    for f in my_fields:
                        if f not in job_stats:
                            job_stats[f] = ""
                    
                    print
                    print my_fmt.format(*my_labels)
                    print my_fmt.format(*(["------------"] * len(my_fields)))
                    print my_fmt.format(*[job_stats[f] for f in my_fields])
    else:
        print "No jobs found matching search criteria"
